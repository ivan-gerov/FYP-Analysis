{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from functools import reduce\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PARTICIPANT = 'par_11'\n",
    "PART_OF_EXPERIMENT = 'part_3'\n",
    "\n",
    "MAIN_DATA_FOLDER = os.path.abspath('../data')\n",
    "\n",
    "if CURRENT_PARTICIPANT not in os.listdir(os.getcwd()):\n",
    "    \n",
    "    PARTICIPANT_OUTPUT_FOLDER = os.path.join(os.getcwd(), CURRENT_PARTICIPANT)\n",
    "    os.mkdir(PARTICIPANT_OUTPUT_FOLDER)\n",
    "    \n",
    "    RAW_FOLDER = os.path.join(PARTICIPANT_OUTPUT_FOLDER, 'raw_files')\n",
    "    os.mkdir(RAW_FOLDER)\n",
    "else: \n",
    "    \n",
    "    PARTICIPANT_OUTPUT_FOLDER = os.path.join(os.getcwd(), CURRENT_PARTICIPANT)\n",
    "    RAW_FOLDER = os.path.join(PARTICIPANT_OUTPUT_FOLDER, 'raw_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(\n",
    "    CURRENT_PARTICIPANT=CURRENT_PARTICIPANT,\n",
    "    PART_OF_EXPERIMENT=PART_OF_EXPERIMENT,\n",
    "    MAIN_DATA_FOLDER=MAIN_DATA_FOLDER,\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads posner_data.csv and sequence_of_conditions.json based on the\n",
    "    current participant and current part of the experiment from the main data folder.\n",
    "    \"\"\"\n",
    "\n",
    "    posner_data_dir = os.path.join(\n",
    "        MAIN_DATA_FOLDER, CURRENT_PARTICIPANT + \"\\\\posner_data\\\\\" + PART_OF_EXPERIMENT\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Load posner data into DataFrame\n",
    "    df = pd.read_csv(os.path.join(posner_data_dir, f\"{PART_OF_EXPERIMENT}.csv\"))\n",
    "\n",
    "    # Load sound condition sequence from JSON\n",
    "    cond_seq = json.load(\n",
    "        open(os.path.join(posner_data_dir, f\"{PART_OF_EXPERIMENT}.json\"))\n",
    "    )\n",
    "\n",
    "    # Convert sound condition names from \"sounds/lofi_track.wav\" to \"lofi_track\"\n",
    "    for key, val in cond_seq.items():\n",
    "        slash_start = val.find(\"/\")\n",
    "        dot_start = val.find(\".\")\n",
    "        cond_seq[key] = val[slash_start + 1 : dot_start]\n",
    "    \n",
    "    for key, val in cond_seq.items():\n",
    "        if 'lofi' in val:\n",
    "            cond_seq[key] = 'lofi'\n",
    "        elif 'pink' in val:\n",
    "            cond_seq[key] = 'white'\n",
    "    \n",
    "    return df, cond_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cond_seq = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'silence', '2': 'lofi', '3': 'white'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_data(df, cond_seq):\n",
    "    \"\"\" \n",
    "    Splits the DataFrame into 3 dataframes based on where we have a row. Returns a dict of dataframes - each one is a sound condition block.\n",
    "    \"\"\"\n",
    "    # Find IDs of the empty rows OR where cueOri is None\n",
    "    empty_rows = np.where(pd.isnull(df['cueOri']))\n",
    "    empty_rows = list(empty_rows[0])\n",
    "\n",
    "    # Transform df into np.ndarray and split it on the IDs of empty rows\n",
    "    sound_conditions = np.array_split(df, empty_rows)\n",
    "\n",
    "    # Due to glitchy PsychoPy script, it returns 4 ndarrays. We take only the first three\n",
    "    sound_conditions = sound_conditions[:3]\n",
    "\n",
    "    # Match index of sound condition from sound_conditions and cond_seq\n",
    "    # and put that into the df_collection\n",
    "    df_collection = {}\n",
    "\n",
    "    for index, condition_data in enumerate(sound_conditions):\n",
    "        df_collection[cond_seq[str(index + 1)]] = condition_data\n",
    "    \n",
    "    return df_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collection = split_data(df, cond_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(cond_name, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Returns a sound condition DataFrame in the correct format + removes all unnecessary columns\n",
    "    \"\"\"\n",
    "    df.rename(\n",
    "        columns={\"correct_key_resp.rt\": \"rt\", \"correct_key_resp.keys\": \"corr_resp\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    df = df.loc[df[\"correct_key_resp.corr\"] == 1.0]\n",
    "    df = df.loc[df[\"early_resp.keys\"] == \"None\"]\n",
    "\n",
    "    # Create condition column\n",
    "    df[\"condition\"] = cond_name\n",
    "\n",
    "    # Create cueValid column\n",
    "    df[\"cueValid\"] = \"\"\n",
    "\n",
    "    # Right Cue + Right Target = Valid\n",
    "    df.loc[(df[\"cueOri\"] == 180.0) & (df[\"targetX\"] == 0.5), \"cueValid\"] = True\n",
    "\n",
    "    # Left Cue + Left Target = Valid\n",
    "    df.loc[(df[\"cueOri\"] == 0.0) & (df[\"targetX\"] == -0.5), \"cueValid\"] = True\n",
    "\n",
    "    # Right Cue + Left Target = Invalid\n",
    "    df.loc[(df[\"cueOri\"] == 180.0) & (df[\"targetX\"] == -0.5), \"cueValid\"] = False\n",
    "\n",
    "    # Left Cue + Right Target = Invalid\n",
    "    df.loc[(df[\"cueOri\"] == 0.0) & (df[\"targetX\"] == 0.5), \"cueValid\"] = False\n",
    "\n",
    "    # Removing all unncessesary columns\n",
    "    df = df.loc[:, [\"condition\", \"cueValid\", \"rt\"]]\n",
    "\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in df_collection.items():\n",
    "    df_collection[key] = transform_df(cond_name= key, df= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in df_collection.items():\n",
    "    val.to_csv(\n",
    "        os.path.join(RAW_FOLDER, f'{key}_{PART_OF_EXPERIMENT}.csv'),\n",
    "        encoding= 'utf8',\n",
    "        index= False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit5ce9db9e7da94f4699f91d5f590f81c0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
